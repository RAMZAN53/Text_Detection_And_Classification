{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2MhnBZkxCJ-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import easyocr\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import pickle\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mount Google Drive ===\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqACHWNlymti",
        "outputId": "39a24e60-fbb8-439b-8a8d-c34313b98a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load model and label encoder ===\n",
        "model_path = '/content/drive/My Drive/ML1_Project/MobileNet/Model6/MobileNetBest_Model.h5'\n",
        "pkl_path = '/content/drive/My Drive/ML1_Project/MobileNet/Model6/MobileNet_Label_Encoder.pkl'\n",
        "\n",
        "model = load_model(model_path)\n",
        "print(\"✅ Model loaded.\")\n",
        "\n",
        "if os.path.exists(pkl_path):\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        label_map = pickle.load(f)\n",
        "        index_to_label = {v: k for k, v in label_map.items()}\n",
        "    print(\"✅ Label encoder loaded.\")\n",
        "else:\n",
        "    index_to_label = {0: \"Handwritten\", 1: \"Computerized\"}\n",
        "    print(\"⚠️ Label encoder not found, using default mapping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4yleODgx7rn",
        "outputId": "eafa358a-5c6e-41b4-c395-cff105e70676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded.\n",
            "✅ Label encoder loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Classification function ===\n",
        "def classify_text_region(region_img):\n",
        "    try:\n",
        "        region_img = cv2.resize(region_img, (224, 224))\n",
        "        region_img = region_img.astype(\"float32\") / 255.0\n",
        "        region_img = img_to_array(region_img)\n",
        "        region_img = np.expand_dims(region_img, axis=0)\n",
        "\n",
        "        preds = model.predict(region_img)\n",
        "\n",
        "        if preds.shape[-1] == 1:\n",
        "            return \"Computerized\" if preds[0][0] > 0.5 else \"Handwritten\"\n",
        "        else:\n",
        "            class_idx = np.argmax(preds[0])\n",
        "            return index_to_label.get(class_idx, \"Unknown\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ Classification error:\", e)\n",
        "        return \"Unknown\""
      ],
      "metadata": {
        "id": "zUYVjStZyNct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === OCR + Annotation ===\n",
        "def AnnotatedTextDetection_EasyOCR_from_array(img):\n",
        "    reader = easyocr.Reader(['en'], gpu=False)\n",
        "    results = reader.readtext(img)\n",
        "    annotated_results = []\n",
        "\n",
        "    for (bbox, text, conf) in results:\n",
        "        if conf < 0.3 or text.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        x1, y1 = map(int, bbox[0])\n",
        "        x2, y2 = map(int, bbox[2])\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        if crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        label = classify_text_region(crop)\n",
        "        annotated_results.append(f\"{text.strip()} → {label}\")\n",
        "\n",
        "        color = (0, 255, 0) if label == \"Computerized\" else (255, 0, 0)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
        "\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB), \"\\n\".join(annotated_results)"
      ],
      "metadata": {
        "id": "gIjuA_sbyOf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Main image processing function ===\n",
        "def process_image(input_image):\n",
        "    img = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
        "    result_img, text_result = AnnotatedTextDetection_EasyOCR_from_array(img)\n",
        "    return result_img, text_result"
      ],
      "metadata": {
        "id": "J6WGl87QySQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62O3NSQBzDOx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}